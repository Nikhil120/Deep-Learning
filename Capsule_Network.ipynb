{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"datasets/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = mnist.train.images\n",
    "test_data = mnist.test.images\n",
    "validation_data = mnist.validation.images\n",
    "\n",
    "print(\"Training -\", len(train_data))\n",
    "print(\"Testing -\", len(test_data))\n",
    "print(\"Validating -\", len(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input variable\n",
    "X = tf.placeholder(shape=[None, 28, 28, 1], dtype=tf.float32, name=\"X\")\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# first convolutional layer\n",
    "conv1 = tf.layers.conv2d(X, filters=256, kernel_size=9, strides=1, padding=\"valid\", activation=tf.nn.relu, name=\"conv1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# second convolutional layer\n",
    "conv2 = tf.layers.conv2d(conv1, filters=256, kernel_size=9, strides=2, padding=\"valid\", activation=tf.nn.relu, name=\"conv2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Capsule Layer hyper parameters\n",
    "caps1_dimension = 8\n",
    "caps1_maps = 32\n",
    "caps1_capsules = 1152     # 32*6*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second convolutional layer reshapes to form a capsule of shape batch_size, 1152, 8\n",
    "caps1 = tf.reshape(conv2, [-1, caps1_capsules, caps1_dimension], name=\"caps1\") \n",
    "caps1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to squash vectors to ensure that their length is between 0 and 1\n",
    "def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "    with tf.name_scope(name, default_name=\"squash\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keepdims=True)\n",
    "        safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "        squash_factor = squared_norm / (1. + squared_norm)\n",
    "        unit_vector = s / safe_norm\n",
    "        return squash_factor * unit_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caps1_output = squash(caps1, name=\"caps1_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps1_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Digit layer hyper paramaeters\n",
    "caps2_capsules = 10\n",
    "caps2_dimension = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_init = tf.random_normal(\n",
    "                          shape=(1, caps1_capsules, caps2_capsules, caps1_dimension, caps2_dimension),\n",
    "                          stddev=0.01, dtype=tf.float32)\n",
    "W = tf.Variable(W_init, name=\"W\")\n",
    "W\n",
    "\n",
    "batch_size = tf.shape(X)[0]\n",
    "\n",
    "W_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1], name=\"W_tiled\")\n",
    "W_tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps1_output_expanded1 = tf.expand_dims(caps1_output, -2, name=\"caps1_output_expanded1\")\n",
    "caps1_output_expanded1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps1_output_expanded2 = tf.expand_dims(caps1_output_expanded1, -3, name=\"caps1_output_expanded2\")\n",
    "caps1_output_expanded2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps1_output_tiled = tf.tile(caps1_output_expanded2, [1, 1, caps2_capsules, 1, 1], name=\"caps1_output_tiled\")\n",
    "caps1_output_tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "caps2_predicted = tf.matmul(caps1_output_tiled, W_tiled, name=\"caps2_perdicted\")\n",
    "caps2_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Routing by agreement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "routing_iterations = 3\n",
    "\n",
    "b = tf.zeros([batch_size, caps1_capsules, caps2_capsules, 1, 1], dtype=tf.float32, name=\"b\")\n",
    "\n",
    "for i in range(routing_iterations):\n",
    "    c = tf.nn.softmax(b, axis=2, name=\"c\")\n",
    "    t = tf.multiply(c, caps2_predicted)\n",
    "    s = tf.reduce_sum(t, axis=1, keepdims=True, name=\"s\")\n",
    "    v = squash(s, axis=2, name=\"v\")\n",
    "    v_tiled = tf.tile(v, [1, caps1_capsules, 1, 1, 1])\n",
    "    agreement = tf.matmul(caps2_predicted, caps2_output_tiled, transpose_b=True, name=\"agreement\")\n",
    "    b = tf.add(b, agreement)\n",
    "    \n",
    "caps2_output = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Estimated class prababilities\n",
    "def safe_norm(s, axis=-1, epsilon=1e-7, keepdims=False, name=None):\n",
    "    with tf.name_scope(name, default_name=\"safe_norm\"):\n",
    "        squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                     keepdims=keepdims)\n",
    "        return tf.sqrt(squared_norm + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob = safe_norm(caps2_output, axis=-1, name=\"y_prob\")\n",
    "y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob_argmax = tf.argmax(y_prob, axis=2, name=\"t_prob_argmax\")\n",
    "y_prob_argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'y_pred:0' shape=(?,) dtype=int64>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = tf.squeeze(y_prob_argmax, axis=[1,2], name=\"y_pred\")\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'y:0' shape=(?,) dtype=int64>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = tf.placeholder(shape=[None], dtype = tf.int64, name=\"y\")\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_plus = 0.9\n",
    "m_minus = 0.1\n",
    "lambda_ = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'T:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = tf.one_hot(y, depth=caps2_capsules, name=\"T\")\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2output_norm/Sqrt:0' shape=(?, 1, 10, 1, 1) dtype=float32>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_output_norm = safe_norm(caps2_output, axis=-1, keepdims=True, name=\"caps2output_norm\")\n",
    "caps2_output_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'present_error:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# square of max(0,m+ - v)\n",
    "\n",
    "present_error_raw = tf.square(tf.maximum(0., m_plus - caps2_output_norm))\n",
    "present_error = tf.reshape(present_error_raw, shape=(-1, 10), name=\"present_error\")\n",
    "present_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'absent_error:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# square of max(0,v - m-)\n",
    "\n",
    "absent_error_raw = tf.square(tf.maximum(0., caps2_output_norm - m_minus), name=\"absent_error_raw\")\n",
    "absent_error = tf.reshape(absent_error_raw, shape=(-1, 10), name=\"absent_error\")\n",
    "absent_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'L:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = tf.add(T * present_error, lambda_ * (1 - T) * absent_error, name=\"L\")\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'margin_loss:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis=1), name=\"margin_loss\")\n",
    "margin_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'mask_with_labels:0' shape=() dtype=bool>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_with_labels = tf.placeholder_with_default(False, shape=(), name=\"mask_with_labels\")\n",
    "mask_with_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'reconstruction_targets/Merge:0' shape=(?,) dtype=int64>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction_targets = tf.cond(mask_with_labels, # condition\n",
    "                                 lambda: y, # if True\n",
    "                                 lambda: y_pred, # if False\n",
    "                                 name=\"reconstruction_targets\")\n",
    "reconstruction_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'resruction_mask:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction_mask = tf.one_hot(reconstruction_targets, depth=caps2_capsules, name=\"resruction_mask\")\n",
    "reconstruction_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'caps2_output_round1_2/mul:0' shape=(?, 1, 10, 1, 16) dtype=float32>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'reconstruction_mask_reshaped:0' shape=(?, 1, 10, 1, 1) dtype=float32>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction_mask_reshaped = tf.reshape(reconstruction_mask, [-1, 1, caps2_capsules, 1, 1], name=\"reconstruction_mask_reshaped\")\n",
    "reconstruction_mask_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'casp2_output_masked:0' shape=(?, 1, 10, 1, 16) dtype=float32>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "caps2_output_masked = tf.multiply(reconstruction_mask_reshaped, caps2_output, name=\"casp2_output_masked\")\n",
    "caps2_output_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'decoder_input:0' shape=(?, 160) dtype=float32>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input = tf.reshape(caps2_output_masked, [-1, caps2_capsules * caps2_dimension], name=\"decoder_input\")\n",
    "decoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden1 = 512\n",
    "n_hidden2 = 1024\n",
    "n_output = 28 * 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"decoder\"):\n",
    "    hidden1 = tf.layers.dense(decoder_input, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    decoder_output = tf.layers.dense(hidden2, n_output, activation=tf.nn.relu, name=\"decoder_output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reconstruction Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_flat = tf.reshape(X, [-1, n_output], name=\"X_flat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "squared_difference = tf.square(X_flat - decoder_output, name=\"squared_difference\")\n",
    "reconstruction_loss = tf.reduce_mean(squared_difference, name=\"reconstruction_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Final loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 0.0005\n",
    "\n",
    "loss = tf.add(margin_loss, alpha * reconstruction_loss, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "\n",
    "correct = tf.equal(y, y_pred, name=\"correct\")\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Operations\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "training_op = optimizer.minimize(loss, name=\"training_op\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init =tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Graph\n",
    "\n",
    "tf.summary.scalar(\"Accuracy\", accuracy)\n",
    "tf.summary.scalar(\"Loss\", loss)\n",
    "tf.summary.scalar(\"Margin_Loss\", margin_loss)\n",
    "tf.summary.scalar(\"Reconstruction_Loss\", reconstruction_loss)\n",
    "\n",
    "merged_summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1  Val accuracy: 98.7600%  Loss: 0.015980 (improved)\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1\n",
    "batch_size = 50\n",
    "restore_checkpoint = True\n",
    "\n",
    "n_iterations_per_epoch = mnist.train.num_examples // batch_size\n",
    "n_iterations_validation = mnist.validation.num_examples // batch_size\n",
    "best_loss_val = np.infty\n",
    "checkpoint_path = \"capsule_network_summary/capsule.ckpt\"\n",
    "summary_path = \"capsule_network_summary/\"\n",
    "\n",
    "with tf.Session() as sess:    \n",
    "    \n",
    "    writer = tf.summary.FileWriter(summary_path, sess.graph)\n",
    "    \n",
    "    if restore_checkpoint and tf.train.checkpoint_exists(checkpoint_path):\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        init.run()\n",
    "        for epoch in range(n_epochs):\n",
    "            for iteration in range(1, n_iterations_per_epoch + 1):\n",
    "                X_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "\n",
    "\n",
    "                # Run the training operation and measure the loss:\n",
    "                _, loss_train, summary_train = sess.run([training_op, loss, merged_summary],\n",
    "                                          feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                                                     y: y_batch,\n",
    "                                                     mask_with_labels:True})\n",
    "\n",
    "                \n",
    "                writer.add_summary(summary_train, iteration)\n",
    "                \n",
    "                print(\"\\rIteration: {}/{} ({:.1f}%)  Loss: {:.5f}\".format(\n",
    "                          iteration, n_iterations_per_epoch,iteration * 100 / n_iterations_per_epoch,loss_train),end=\"\")\n",
    "\n",
    "            # At the end of each epoch,\n",
    "            # measure the validation loss and accuracy:\n",
    "            loss_vals = []\n",
    "            acc_vals = []\n",
    "            for iteration in range(1, n_iterations_validation + 1):\n",
    "                X_batch, y_batch = mnist.validation.next_batch(batch_size)\n",
    "                loss_val, acc_val = sess.run([loss, accuracy],\n",
    "                                             feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),\n",
    "                                                        y: y_batch})\n",
    "                loss_vals.append(loss_val)\n",
    "                acc_vals.append(acc_val)\n",
    "                print(\"\\rEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                          iteration, n_iterations_validation,\n",
    "                          iteration * 100 / n_iterations_validation),\n",
    "                      end=\" \" * 10)\n",
    "            loss_val = np.mean(loss_vals)\n",
    "            acc_val = np.mean(acc_vals)\n",
    "            print(\"\\rEpoch: {}  Val accuracy: {:.4f}%  Loss: {:.6f}{}\".format(\n",
    "                        epoch + 1, acc_val * 100, loss_val, \" (improved)\" if loss_val < best_loss_val else \"\"))\n",
    "\n",
    "            # And save the model if it improved:\n",
    "            if loss_val < best_loss_val:\n",
    "                save_path = saver.save(sess, checkpoint_path)\n",
    "                best_loss_val = loss_val\n",
    "\n",
    "                writer = tf.summary.FileWriter(summary_path, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from capsule_network_summary/capsule.ckpt\n",
      "\n",
      "Evaluating the model: 0/200 (0.0%)          \n",
      "Evaluating the model: 1/200 (0.5%)          \n",
      "Evaluating the model: 2/200 (1.0%)          \n",
      "Evaluating the model: 3/200 (1.5%)          \n",
      "Evaluating the model: 4/200 (2.0%)          \n",
      "Evaluating the model: 5/200 (2.5%)          \n",
      "Evaluating the model: 6/200 (3.0%)          \n",
      "Evaluating the model: 7/200 (3.5%)          \n",
      "Evaluating the model: 8/200 (4.0%)          \n",
      "Evaluating the model: 9/200 (4.5%)          \n",
      "Evaluating the model: 10/200 (5.0%)          \n",
      "Evaluating the model: 11/200 (5.5%)          \n",
      "Evaluating the model: 12/200 (6.0%)          \n",
      "Evaluating the model: 13/200 (6.5%)          \n",
      "Evaluating the model: 14/200 (7.0%)          \n",
      "Evaluating the model: 15/200 (7.5%)          \n",
      "Evaluating the model: 16/200 (8.0%)          \n",
      "Evaluating the model: 17/200 (8.5%)          \n",
      "Evaluating the model: 18/200 (9.0%)          \n",
      "Evaluating the model: 19/200 (9.5%)          \n",
      "Evaluating the model: 20/200 (10.0%)          \n",
      "Evaluating the model: 21/200 (10.5%)          \n",
      "Evaluating the model: 22/200 (11.0%)          \n",
      "Evaluating the model: 23/200 (11.5%)          \n",
      "Evaluating the model: 24/200 (12.0%)          \n",
      "Evaluating the model: 25/200 (12.5%)          \n",
      "Evaluating the model: 26/200 (13.0%)          \n",
      "Evaluating the model: 27/200 (13.5%)          \n",
      "Evaluating the model: 28/200 (14.0%)          \n",
      "Evaluating the model: 29/200 (14.5%)          \n",
      "Evaluating the model: 30/200 (15.0%)          \n",
      "Evaluating the model: 31/200 (15.5%)          \n",
      "Evaluating the model: 32/200 (16.0%)          \n",
      "Evaluating the model: 33/200 (16.5%)          \n",
      "Evaluating the model: 34/200 (17.0%)          \n",
      "Evaluating the model: 35/200 (17.5%)          \n",
      "Evaluating the model: 36/200 (18.0%)          \n",
      "Evaluating the model: 37/200 (18.5%)          \n",
      "Evaluating the model: 38/200 (19.0%)          \n",
      "Evaluating the model: 39/200 (19.5%)          \n",
      "Evaluating the model: 40/200 (20.0%)          \n",
      "Evaluating the model: 41/200 (20.5%)          \n",
      "Evaluating the model: 42/200 (21.0%)          \n",
      "Evaluating the model: 43/200 (21.5%)          \n",
      "Evaluating the model: 44/200 (22.0%)          \n",
      "Evaluating the model: 45/200 (22.5%)          \n",
      "Evaluating the model: 46/200 (23.0%)          \n",
      "Evaluating the model: 47/200 (23.5%)          \n",
      "Evaluating the model: 48/200 (24.0%)          \n",
      "Evaluating the model: 49/200 (24.5%)          \n",
      "Evaluating the model: 50/200 (25.0%)          \n",
      "Evaluating the model: 51/200 (25.5%)          \n",
      "Evaluating the model: 52/200 (26.0%)          \n",
      "Evaluating the model: 53/200 (26.5%)          \n",
      "Evaluating the model: 54/200 (27.0%)          \n",
      "Evaluating the model: 55/200 (27.5%)          \n",
      "Evaluating the model: 56/200 (28.0%)          \n",
      "Evaluating the model: 57/200 (28.5%)          \n",
      "Evaluating the model: 58/200 (29.0%)          \n",
      "Evaluating the model: 59/200 (29.5%)          \n",
      "Evaluating the model: 60/200 (30.0%)          \n",
      "Evaluating the model: 61/200 (30.5%)          \n",
      "Evaluating the model: 62/200 (31.0%)          \n",
      "Evaluating the model: 63/200 (31.5%)          \n",
      "Evaluating the model: 64/200 (32.0%)          \n",
      "Evaluating the model: 65/200 (32.5%)          \n",
      "Evaluating the model: 66/200 (33.0%)          \n",
      "Evaluating the model: 67/200 (33.5%)          \n",
      "Evaluating the model: 68/200 (34.0%)          \n",
      "Evaluating the model: 69/200 (34.5%)          \n",
      "Evaluating the model: 70/200 (35.0%)          \n",
      "Evaluating the model: 71/200 (35.5%)          \n",
      "Evaluating the model: 72/200 (36.0%)          \n",
      "Evaluating the model: 73/200 (36.5%)          \n",
      "Evaluating the model: 74/200 (37.0%)          \n",
      "Evaluating the model: 75/200 (37.5%)          \n",
      "Evaluating the model: 76/200 (38.0%)          \n",
      "Evaluating the model: 77/200 (38.5%)          \n",
      "Evaluating the model: 78/200 (39.0%)          \n",
      "Evaluating the model: 79/200 (39.5%)          \n",
      "Evaluating the model: 80/200 (40.0%)          \n",
      "Evaluating the model: 81/200 (40.5%)          \n",
      "Evaluating the model: 82/200 (41.0%)          \n",
      "Evaluating the model: 83/200 (41.5%)          \n",
      "Evaluating the model: 84/200 (42.0%)          \n",
      "Evaluating the model: 85/200 (42.5%)          \n",
      "Evaluating the model: 86/200 (43.0%)          \n",
      "Evaluating the model: 87/200 (43.5%)          \n",
      "Evaluating the model: 88/200 (44.0%)          \n",
      "Evaluating the model: 89/200 (44.5%)          \n",
      "Evaluating the model: 90/200 (45.0%)          \n",
      "Evaluating the model: 91/200 (45.5%)          \n",
      "Evaluating the model: 92/200 (46.0%)          \n",
      "Evaluating the model: 93/200 (46.5%)          \n",
      "Evaluating the model: 94/200 (47.0%)          \n",
      "Evaluating the model: 95/200 (47.5%)          \n",
      "Evaluating the model: 96/200 (48.0%)          \n",
      "Evaluating the model: 97/200 (48.5%)          \n",
      "Evaluating the model: 98/200 (49.0%)          \n",
      "Evaluating the model: 99/200 (49.5%)          \n",
      "Evaluating the model: 100/200 (50.0%)          \n",
      "Evaluating the model: 101/200 (50.5%)          \n",
      "Evaluating the model: 102/200 (51.0%)          \n",
      "Evaluating the model: 103/200 (51.5%)          \n",
      "Evaluating the model: 104/200 (52.0%)          \n",
      "Evaluating the model: 105/200 (52.5%)          \n",
      "Evaluating the model: 106/200 (53.0%)          \n",
      "Evaluating the model: 107/200 (53.5%)          \n",
      "Evaluating the model: 108/200 (54.0%)          \n",
      "Evaluating the model: 109/200 (54.5%)          \n",
      "Evaluating the model: 110/200 (55.0%)          \n",
      "Evaluating the model: 111/200 (55.5%)          \n",
      "Evaluating the model: 112/200 (56.0%)          \n",
      "Evaluating the model: 113/200 (56.5%)          \n",
      "Evaluating the model: 114/200 (57.0%)          \n",
      "Evaluating the model: 115/200 (57.5%)          \n",
      "Evaluating the model: 116/200 (58.0%)          \n",
      "Evaluating the model: 117/200 (58.5%)          \n",
      "Evaluating the model: 118/200 (59.0%)          \n",
      "Evaluating the model: 119/200 (59.5%)          \n",
      "Evaluating the model: 120/200 (60.0%)          \n",
      "Evaluating the model: 121/200 (60.5%)          \n",
      "Evaluating the model: 122/200 (61.0%)          \n",
      "Evaluating the model: 123/200 (61.5%)          \n",
      "Evaluating the model: 124/200 (62.0%)          \n",
      "Evaluating the model: 125/200 (62.5%)          \n",
      "Evaluating the model: 126/200 (63.0%)          \n",
      "Evaluating the model: 127/200 (63.5%)          \n",
      "Evaluating the model: 128/200 (64.0%)          \n",
      "Evaluating the model: 129/200 (64.5%)          \n",
      "Evaluating the model: 130/200 (65.0%)          \n",
      "Evaluating the model: 131/200 (65.5%)          \n",
      "Evaluating the model: 132/200 (66.0%)          \n",
      "Evaluating the model: 133/200 (66.5%)          \n",
      "Evaluating the model: 134/200 (67.0%)          \n",
      "Evaluating the model: 135/200 (67.5%)          \n",
      "Evaluating the model: 136/200 (68.0%)          \n",
      "Evaluating the model: 137/200 (68.5%)          \n",
      "Evaluating the model: 138/200 (69.0%)          \n",
      "Evaluating the model: 139/200 (69.5%)          \n",
      "Evaluating the model: 140/200 (70.0%)          \n",
      "Evaluating the model: 141/200 (70.5%)          \n",
      "Evaluating the model: 142/200 (71.0%)          \n",
      "Evaluating the model: 143/200 (71.5%)          \n",
      "Evaluating the model: 144/200 (72.0%)          \n",
      "Evaluating the model: 145/200 (72.5%)          \n",
      "Evaluating the model: 146/200 (73.0%)          \n",
      "Evaluating the model: 147/200 (73.5%)          \n",
      "Evaluating the model: 148/200 (74.0%)          \n",
      "Evaluating the model: 149/200 (74.5%)          \n",
      "Evaluating the model: 150/200 (75.0%)          \n",
      "Evaluating the model: 151/200 (75.5%)          \n",
      "Evaluating the model: 152/200 (76.0%)          \n",
      "Evaluating the model: 153/200 (76.5%)          \n",
      "Evaluating the model: 154/200 (77.0%)          \n",
      "Evaluating the model: 155/200 (77.5%)          \n",
      "Evaluating the model: 156/200 (78.0%)          \n",
      "Evaluating the model: 157/200 (78.5%)          \n",
      "Evaluating the model: 158/200 (79.0%)          \n",
      "Evaluating the model: 159/200 (79.5%)          \n",
      "Evaluating the model: 160/200 (80.0%)          \n",
      "Evaluating the model: 161/200 (80.5%)          \n",
      "Evaluating the model: 162/200 (81.0%)          \n",
      "Evaluating the model: 163/200 (81.5%)          \n",
      "Evaluating the model: 164/200 (82.0%)          \n",
      "Evaluating the model: 165/200 (82.5%)          \n",
      "Evaluating the model: 166/200 (83.0%)          \n",
      "Evaluating the model: 167/200 (83.5%)          \n",
      "Evaluating the model: 168/200 (84.0%)          \n",
      "Evaluating the model: 169/200 (84.5%)          \n",
      "Evaluating the model: 170/200 (85.0%)          \n",
      "Evaluating the model: 171/200 (85.5%)          \n",
      "Evaluating the model: 172/200 (86.0%)          \n",
      "Evaluating the model: 173/200 (86.5%)          \n",
      "Evaluating the model: 174/200 (87.0%)          \n",
      "Evaluating the model: 175/200 (87.5%)          \n",
      "Evaluating the model: 176/200 (88.0%)          \n",
      "Evaluating the model: 177/200 (88.5%)          \n",
      "Evaluating the model: 178/200 (89.0%)          \n",
      "Evaluating the model: 179/200 (89.5%)          \n",
      "Evaluating the model: 180/200 (90.0%)          \n",
      "Evaluating the model: 181/200 (90.5%)          \n",
      "Evaluating the model: 182/200 (91.0%)          \n",
      "Evaluating the model: 183/200 (91.5%)          \n",
      "Evaluating the model: 184/200 (92.0%)          \n",
      "Evaluating the model: 185/200 (92.5%)          \n",
      "Evaluating the model: 186/200 (93.0%)          \n",
      "Evaluating the model: 187/200 (93.5%)          \n",
      "Evaluating the model: 188/200 (94.0%)          \n",
      "Evaluating the model: 189/200 (94.5%)          \n",
      "Evaluating the model: 190/200 (95.0%)          \n",
      "Evaluating the model: 191/200 (95.5%)          \n",
      "Evaluating the model: 192/200 (96.0%)          \n",
      "Evaluating the model: 193/200 (96.5%)          \n",
      "Evaluating the model: 194/200 (97.0%)          \n",
      "Evaluating the model: 195/200 (97.5%)          \n",
      "Evaluating the model: 196/200 (98.0%)          \n",
      "Evaluating the model: 197/200 (98.5%)          \n",
      "Evaluating the model: 198/200 (99.0%)          \n",
      "Evaluating the model: 199/200 (99.5%)          \n",
      "Final test accuracy: 98.7065%  Loss: 0.016119   \n"
     ]
    }
   ],
   "source": [
    "n_iterations_test = mnist.test.num_examples // batch_size\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver.restore(sess, checkpoint_path)\n",
    "    \n",
    "    loss_tests = []\n",
    "    acc_tests = []\n",
    "    \n",
    "    for iteration in range(n_iterations_test + 1):\n",
    "        X_batch, y_batch = mnist.test.next_batch(batch_size)\n",
    "        \n",
    "        loss_test, acc_test = sess.run([loss, accuracy], \n",
    "                                       feed_dict = {X: X_batch.reshape([-1, 28, 28, 1]), \n",
    "                                                    y: y_batch})\n",
    "        loss_tests.append(loss_test)\n",
    "        acc_tests.append(acc_test)\n",
    "        \n",
    "        \n",
    "        print(\"\\nEvaluating the model: {}/{} ({:.1f}%)\".format(\n",
    "                    iteration, n_iterations_test, iteration * 100 / n_iterations_test), end=\" \" * 10)\n",
    "        \n",
    "    loss_test = np.mean(loss_tests)\n",
    "    acc_test = np.mean(acc_tests)\n",
    "        \n",
    "    print(\"\\rFinal test accuracy: {:.4f}%  Loss: {:.6f}\".format(acc_test * 100, loss_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tensorboard --logdir=\"C:/Users/Admin/Documents/anaconda files\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
